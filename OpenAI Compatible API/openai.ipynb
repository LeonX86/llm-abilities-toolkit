{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "89d91e42",
      "metadata": {},
      "source": [
        "## 导入config模块路径"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9a39f4da",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['c:\\\\Users\\\\Leon\\\\miniforge3\\\\envs\\\\cm312\\\\python312.zip', 'c:\\\\Users\\\\Leon\\\\miniforge3\\\\envs\\\\cm312\\\\DLLs', 'c:\\\\Users\\\\Leon\\\\miniforge3\\\\envs\\\\cm312\\\\Lib', 'c:\\\\Users\\\\Leon\\\\miniforge3\\\\envs\\\\cm312', '', 'c:\\\\Users\\\\Leon\\\\miniforge3\\\\envs\\\\cm312\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\Leon\\\\miniforge3\\\\envs\\\\cm312\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\Leon\\\\miniforge3\\\\envs\\\\cm312\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\Leon\\\\miniforge3\\\\envs\\\\cm312\\\\Lib\\\\site-packages\\\\Pythonwin', 'c:\\\\WorkFlow\\\\E\\\\Code\\\\Python\\\\llm-abilities-toolkit']\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "str(Path.cwd().parent) in sys.path or sys.path.append(str(Path.cwd().parent))\n",
        "print(sys.path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea549cac",
      "metadata": {},
      "source": [
        "## 使用模块管理api-key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41736183",
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from config import config\n",
        "\n",
        "# 使用 ** 解包创建客户端\n",
        "client = OpenAI(**config.get_nvidia_config())\n",
        "\n",
        "# 创建聊天补全\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"minimaxai/minimax-m2.1\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"你是谁？\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Response:\")\n",
        "print(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9660a2a5",
      "metadata": {},
      "source": [
        "## 基础调用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57117daf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response:\n",
            "<think>用户用中文问\"你是谁？\"，意思是\"Who are you?\"\n",
            "\n",
            "根据系统提示，我是MiniMax-M2.1，由MiniMax公司开发的AI助手。我需要用中文回答这个问题。\n",
            "</think>\n",
            "\n",
            "你好！我是 MiniMax-M2.1，由 MiniMax 公司开发的 AI 助手。有什么我可以帮助你的吗？\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# 初始化客户端\n",
        "client = OpenAI(\n",
        "    base_url=\"https://integrate.api.nvidia.com/v1\",\n",
        "    api_key=\"\"  # 替换为你的 NVIDIA API key\n",
        ")\n",
        "\n",
        "# 创建聊天补全 - 最简版本（只有必需参数）\n",
        "completion = client.chat.completions.create(\n",
        "    # model=\"z-ai/glm4.7\",  # 必需：模型名称\n",
        "    model=\"minimaxai/minimax-m2.1\",\n",
        "    messages=[  # 必需：消息列表\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"你是谁？\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Response:\")\n",
        "print(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bae0381f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response:\n",
            "我是Z.ai开发的GLM大语言模型，通过大规模文本数据训练而成。我致力于提供信息查询、知识解答和创意辅助等服务，同时持续学习和改进以更好地帮助用户。\n",
            "\n",
            "有什么我能帮你解答的问题或提供协助的领域吗？\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# 初始化客户端\n",
        "client = OpenAI(\n",
        "    base_url=\"https://integrate.api.nvidia.com/v1\",\n",
        "    api_key=\"\"\n",
        ")\n",
        "\n",
        "# 创建聊天补全 - 添加 system 消息可能有助于某些模型\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"z-ai/glm4.7\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"你是谁？\"\n",
        "        }\n",
        "    ],\n",
        "    max_tokens=1024,  # 添加 max_tokens 参数\n",
        "    temperature=0.7    # 可选：添加温度参数\n",
        ")\n",
        "\n",
        "print(\"Response:\")\n",
        "print(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6f9c814",
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# 初始化客户端\n",
        "client = OpenAI(\n",
        "    base_url=\"https://integrate.api.nvidia.com/v1\",\n",
        "    api_key=\"nvapi-your-api-key-here\"  # 替换为你的 NVIDIA API key\n",
        ")\n",
        "\n",
        "# 创建聊天补全 - 最简版本（只有必需参数）\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"mistralai/mistral-7b-instruct-v0.3\",  # 必需：模型名称\n",
        "    messages=[  # 必需：消息列表\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Hello! Can you explain what machine learning is?\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 如果需要更多控制，可以添加可选参数：\n",
        "# completion = client.chat.completions.create(\n",
        "#     model=\"mistralai/mistral-7b-instruct-v0.3\",\n",
        "#     messages=[\n",
        "#         {\n",
        "#             \"role\": \"system\",  # 可选：设定 AI 行为\n",
        "#             \"content\": \"You are a helpful AI assistant.\"\n",
        "#         },\n",
        "#         {\n",
        "#             \"role\": \"user\",\n",
        "#             \"content\": \"Hello! Can you explain what machine learning is?\"\n",
        "#         }\n",
        "#     ],\n",
        "#     temperature=0.7,    # 可选：控制随机性，默认 1.0\n",
        "#     max_tokens=1024,    # 可选：限制输出长度\n",
        "#     top_p=0.9,          # 可选：核采样参数，默认 1.0\n",
        "#     stream=False        # 可选：是否流式输出，默认 False\n",
        "# )\n",
        "\n",
        "# 打印响应\n",
        "print(\"Response:\")\n",
        "print(completion.choices[0].message.content)\n",
        "\n",
        "# 如果需要使用流式输出，可以这样修改：\n",
        "# print(\"\\n--- Stream Mode ---\")\n",
        "# stream_completion = client.chat.completions.create(\n",
        "#     model=\"mistralai/mistral-7b-instruct-v0.3\",\n",
        "#     messages=[\n",
        "#         {\n",
        "#             \"role\": \"user\",\n",
        "#             \"content\": \"Write a short poem about AI.\"\n",
        "#         }\n",
        "#     ],\n",
        "#     temperature=0.7,\n",
        "#     max_tokens=512,\n",
        "#     stream=True\n",
        "# )\n",
        "# \n",
        "# for chunk in stream_completion:\n",
        "#     if chunk.choices[0].delta.content is not None:\n",
        "#         print(chunk.choices[0].delta.content, end=\"\", flush=True)\n",
        "# print(\"\\n\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cm312",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
